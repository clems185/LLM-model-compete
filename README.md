# 大语言模型对比分析项目 README
## 一、项目简介
本项目围绕通义千问（Qwen - 7B - Chat ）、智谱（ChatGLM3 - 6B ）、DeepSeek - r1:7b 三种大语言模型展开深度对比分析。通过对五个典型语言问题（语义区别、歧义解析、逻辑悖论、语法解构、多义词语境辨析 ）的回答表现拆解，挖掘各模型在语境理解、逻辑推理、语法分析、语义辨析等维度的优劣，为不同场景下模型选型及应用提供参考，助力探索大语言模型能力边界与适配方向。

## 二、文件结构说明
```

├── 大语言模型对比分析          # 存放所有详细截图示例，辅助直观理解模型表现差异
│   └── [截图文件1.png, 截图文件2.png, ...]
├── 自述文件.md                 # 项目背景、初衷及整体说明文档，快速了解项目价值
├── 运行_chatglm_cpu.ipynb      # 智谱 (ChatGLM3 - 6B) 模型在 CPU 环境运行示例 Python 文件，含调用逻辑、测试代码
├── 运行_qwen_cpu.py            # 通义千问 (Qwen - 7B - Chat) 模型 CPU 环境运行示例 Python 文件，实现模型调用与功能测试
└── 大语言模型横向对比报告.docx  # 完整对比分析报告，含各问题模型表现拆解、综合优劣总结、适用场景建议等核心内容
```

## 三、环境依赖
### （一）通用依赖
- **Python 版本**：建议使用 Python 3.10 及以上版本，保障代码兼容性与稳定性。
- **基础库**：`numpy`（用于数据简单处理，若涉及结果量化分析 ）、`pandas`（如需对模型输出数据结构化整理 ），可通过 `pip install numpy pandas` 安装。

### （二）模型运行依赖（以示例文件为准，不同模型有差异 ）
1. **通义千问（Qwen - 7B - Chat ）**：  
   若使用 `运行_qwen_cpu.py`，需遵循官方 SDK 或 API 调用指引，安装对应依赖包（如官方 Python 客户端 ），并配置有效访问密钥（若涉及远程调用 ）。  
   本地部署需满足模型对硬件（CPU、内存等 ）的最低要求，参考官方文档准备环境。
2. **智谱（ChatGLM3 - 6B ）**：  
   对于 `运行_chatglm_cpu.ipynb`，需安装 `torch`（建议稳定版，适配 CPU 计算 ）、`transformers`（用于加载模型与 tokenizer ），命令：`pip install torch transformers` 。  
   依据模型部署说明，确认模型权重文件路径配置正确，保障加载运行。

## 四、快速启动指南
### （一）查看对比报告
直接打开 `大语言模型横向对比报告.docx`，文档涵盖：  
- 五个问题场景下，三种模型回答的优点、缺点逐点分析；  
- 模型综合优劣总结，清晰呈现能力边界；  
- 适用场景建议，指导不同需求下模型选型。

### （二）运行模型示例文件
1. **通义千问运行示例（运行_qwen_cpu.py ）**：  
   - 步骤 1：确保已安装依赖（参考 “环境依赖” 部分 ），若需远程调用，在代码中填入合法访问密钥、配置 API 地址。  
   - 步骤 2：打开终端，进入项目目录，执行 `python 运行_qwen_cpu.py` ，查看模型调用流程、测试输出，可修改测试问题，探索模型响应。  
2. **智谱运行示例（运行_chatglm_cpu.ipynb ）**：  
   - 步骤 1：安装 `torch`、`transformers` 等依赖（`pip install torch transformers` ），准备好模型权重文件（或配置合法加载路径 ）。  
   - 步骤 2：启动 Jupyter Notebook（`jupyter notebook` ），在浏览器中打开 `运行_chatglm_cpu.ipynb` ，逐单元格运行代码，观察模型加载、问题交互过程，可调整输入问题，测试不同场景表现。




